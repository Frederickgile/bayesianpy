{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification on the Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example gives an idea about how you could run basic classification using a Gaussian mixture model on the Titanic dataset, using a latent node, continuous variables as well as discrete variables. The example uses cross validation to get a more robust accuracy score across the training and testing data sets.\n",
    "\n",
    "The initial step is our imports, and a bit of code for extracting floor and room number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../bayespy\")\n",
    "import bayespy\n",
    "import bayespy.visual\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pattern = re.compile(\"([A-Z]{1})([0-9]{1,3})\")\n",
    "\n",
    "def get_cabin_floor_and_number(cabin):\n",
    "    if not isinstance(cabin, str):\n",
    "        return \"\", np.nan\n",
    "\n",
    "    cabins = cabin.split(\" \")\n",
    "    for cabin in cabins:\n",
    "        match = re.match(pattern, cabin)\n",
    "        if match is not None:\n",
    "            floor = match.group(1)\n",
    "            number = match.group(2)\n",
    "\n",
    "            return floor, number\n",
    "    return \"\", np.nan\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is a bit of preprocessing to get the data in the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db_folder = bayespy.utils.get_path_to_parent_dir(\"\")\n",
    "titanic = pd.read_csv(os.path.join(db_folder, \"data/titanic.csv\"))\n",
    "\n",
    "titanic['Floor'], titanic['CabinNumber'] = zip(*titanic.Cabin.map(get_cabin_floor_and_number))\n",
    "titanic.CabinNumber = titanic.CabinNumber.astype(float)\n",
    "titanic.Floor.replace(\"\", np.nan, inplace=True)\n",
    "\n",
    "# drop variables that vary too much, e.g. with almost every row\n",
    "titanic.drop(['Cabin', 'Ticket', 'Name', 'PassengerId'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's then necessary to attach the thread to the JVM through a pipe created by Jpype (otherwise you get a recursion error message)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayespy.jni.attach(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few basic utility functions for deciding on the type of the data provided - obviously if you're already aware of the type then it's more accurate to manually specify datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete variables: ['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Floor']\n",
      "Continuous variables: ['Age', 'Fare', 'CabinNumber']\n"
     ]
    }
   ],
   "source": [
    "auto = bayespy.data.AutoType(titanic)\n",
    "network_factory = bayespy.network.NetworkFactory(logger)\n",
    "\n",
    "discrete = titanic[list(auto.get_discrete_variables())]\n",
    "continuous = titanic[list(auto.get_continuous_variables())]\n",
    "\n",
    "print(\"Discrete variables: {}\".format(discrete.columns.tolist()))\n",
    "print(\"Continuous variables: {}\".format(continuous.columns.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure will look something like the following (as visualised in networkx). Bayes Server does have a UI, so you could save the model that you generate through the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write data to the temporary sqllite db\n",
    "with bayespy.data.DataSet(titanic, db_folder, logger) as dataset:\n",
    "\n",
    "    # Use a standard template, which generally gives good performance\n",
    "    mixture_naive_bayes_tpl = bayespy.template.MixtureNaiveBayes(logger, discrete=discrete, continuous=continuous)\n",
    "    model = bayespy.model.NetworkModel(\n",
    "                        mixture_naive_bayes_tpl.create(network_factory),\n",
    "                        logger)\n",
    "\n",
    "        # result contains a bunch of metrics regarding the training step\n",
    "    results = model.train(dataset.subset(train_indexes))\n",
    "\n",
    "layout = bayespy.visual.NetworkLayout(results.get_network())\n",
    "graph = layout.build_graph()\n",
    "pos = layout.fruchterman_reingold_layout(graph)\n",
    "layout.visualise(graph, pos)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the code through 3 folds to get an average score from three different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write data to the temporary sqllite db\n",
    "with bayespy.data.DataSet(titanic, db_folder, logger) as dataset:\n",
    "\n",
    "    # Use a standard template, which generally gives good performance\n",
    "    mixture_naive_bayes_tpl = bayespy.template.MixtureNaiveBayes(logger, discrete=discrete, continuous=continuous)\n",
    "\n",
    "    k_folds = 3\n",
    "\n",
    "    kf = KFold(titanic.shape[0], n_folds=k_folds, shuffle=True)\n",
    "    score = 0\n",
    "    # use cross validation to try and predict whether the individual survived or not\n",
    "    for k, (train_indexes, test_indexes) in enumerate(kf):\n",
    "        model = bayespy.model.NetworkModel(\n",
    "                        mixture_naive_bayes_tpl.create(network_factory),\n",
    "                        logger)\n",
    "\n",
    "        # result contains a bunch of metrics regarding the training step\n",
    "        model.train(dataset.subset(train_indexes))\n",
    "\n",
    "        # note that we've not 'dropped' the target data anywhere, this will be retracted when it's queried,\n",
    "        # by specifying query_options.setQueryEvidenceMode(bayesServerInference().QueryEvidenceMode.RETRACT_QUERY_EVIDENCE)\n",
    "        results = model.batch_query(dataset.subset(test_indexes), bayespy.model.QueryMostLikelyState(\"Survived\", \n",
    "                                                                            output_dtype=titanic['Survived'].dtype))\n",
    "\n",
    "        # Each query just appends a column/ columns on to the original dataframe, so results is the same as titanic.iloc[test_indexes],\n",
    "        # with (in this case) one additional column called 'Survived_maxlikelihood', joined to the original.\n",
    "        score += accuracy_score(y_pred=results['Survived_maxlikelihood'].tolist(), \n",
    "                                y_true=results['Survived'].tolist())\n",
    "        \n",
    "logger.info(\"Average score was {}. Baseline accuracy is about 0.61.\".format(score / k_folds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

# -*- coding: utf-8 -*-
"""
Created on Tue Apr 19 16:31:18 2016

@author: imorgan.admin
"""

from bayespy.jni import bayesServerInference

import bayespy.network
import pandas as pd
from bayespy.jni import bayesServer
from bayespy.jni import bayesServerParams
from bayespy.jni import jp
import numpy as np
import logging
import pathos.multiprocessing as mp
from typing import List

class QueryOutput:
    def __init__(self, continuous, discrete):
        self.continuous = continuous
        self.discrete = discrete

class InferenceEngine:

    _inference_factory = None

    def __init__(self, network):
        self._network = network

    @staticmethod
    def get_inference_factory():
        if InferenceEngine._inference_factory is None:
            InferenceEngine._inference_factory = bayesServerInference().RelevanceTreeInferenceFactory()
        return InferenceEngine._inference_factory

    def create(self, loglikelihood=False, conflict=False, retract=False):
        query_options = self.get_inference_factory().createQueryOptions()
        query_output = self.get_inference_factory().createQueryOutput()
        inference_engine = self.get_inference_factory().createInferenceEngine(self._network)

        query_options.setLogLikelihood(loglikelihood)
        query_options.setConflict(conflict)

        if retract:
            query_options.setQueryEvidenceMode(bayesServerInference().QueryEvidenceMode.RETRACT_QUERY_EVIDENCE)

        return inference_engine, query_options, query_output

class Query:


    def __init__(self, jnetwork, inference):
        self._factory = bayesServerInference().RelevanceTreeInferenceFactory()
        self._queryOptions = self._factory.createQueryOptions()
        self._queryOutput = self._factory.createQueryOutput()
        self._queryDistributions = inference.getQueryDistributions()
        self._inference = inference
        self._jnetwork = jnetwork

    def execute(self, variables=None):
        """
        Query a number of variables (if none, then query all variables in the network)
        :param variables: a list of variables, or none
        :return: a QueryOutput object with separate continuous/ discrete dataframes
        """
        distributions = {}
        if variables is None:
            variables = self._jnetwork.getVariables()

        for v in variables:
            if bayespy.network.is_variable_discrete(v):
                table = bayesServer().Table(v)
            else:
                table = bayesServer().CLGaussian(v)

            self._queryDistributions.add(bayesServerInference().QueryDistribution(table))
            distributions.update({ v.getName() : table})

        self._inference.query(self._queryOptions, self._queryOutput)

        states= []
        d_variables = []
        values = []
        c_variables = []
        mean = []
        variance = []
        for v in variables:
            dist =  distributions[v.getName()]
            if bayespy.network.is_variable_discrete(v):
                for state in v.getStates():
                    states.append(state.getName())
                    values.append(float(dist.get([state])))
                    d_variables.append(v.getName())
            else:
                variance.append(float(dist.getVariance(v)))
                mean.append(float(dist.getMean(v)))
                c_variables.append(v.getName())

        return QueryOutput(pd.DataFrame({ 'variable': c_variables, 'mean': mean, 'variance': variance}), pd.DataFrame({ 'variable' : d_variables, 'state': states, 'value' : values}))

class Evidence:

    def __init__(self, jnetwork, inference):
        self._jnetwork = jnetwork
        self._inference = inference
        self._evidence = inference.getEvidence()
        self._evidence.clear()
        self._variables = jnetwork.getVariables()

    def apply(self, evidence):
        """
        Apply evidence to a network
        :param evidence: if a discrete variable, then a list of strings generated by network.Discrete.tostring(),
        if continuous, then a list of tuples with (VariableName, ContinuousValue)
        :return: Nothing
        """
        for value in evidence:
            if not isinstance(value, tuple):
                value = str(value)
                node, state = value.split(bayespy.network.STATE_DELIMITER)
                v = self._variables.get(node)
                if v is None:
                    raise ValueError("Node {} does not exist".format(node))
                if bayespy.network.is_variable_discrete(v):
                    st = v.getStates().get(state)
                    if st is None:
                        raise ValueError("State {} does not exist in variable {}".format(state, node))

                    self._evidence.setState(st)
                else:
                    raise ValueError("Can not find state on a continuous variable")
            else:
                v = self._variables.get(value[0])
                if not bayespy.network.is_variable_continuous(v):
                    raise ValueError("Variable is not continuous")

                self._evidence.set(v, jp.java.lang.Double(value[1]))

        return self._evidence

class QueryStatistics:

    def __init__(self, calc_loglikelihood=True, calc_conflict=False, loglikelihood_column='loglikelihood', conflict_column='conflict'):
        self._calc_loglikelihood = calc_loglikelihood
        self._calc_conflict = calc_conflict
        self._loglikelihood_column = loglikelihood_column
        self._conflict_column = conflict_column

    def setup(self, network, inference_engine, query_options):
        query_options.setLogLikelihood(self._calc_loglikelihood)
        query_options.setConflict(self._calc_conflict)

    def results(self, inference_engine, query_output):
        result = {}
        if self._calc_loglikelihood:
            result.update({ self._loglikelihood_column: query_output.getLogLikelihood().floatValue() })

        if self._calc_conflict:
            result.update({ self._conflict_column: query_output.getConflict().floatValue()})

        return result

# seems like a better name than QueryStatistics, so just having this here.
class QueryModelStatistics(QueryStatistics):
    def __init__(self, calc_loglikelihood=True, calc_conflict=False, loglikelihood_column='loglikelihood', conflict_column='conflict'):
        super().__init__(calc_loglikelihood, calc_conflict, loglikelihood_column, conflict_column)

class QueryMostLikelyState:

    def __init__(self, target_variable_name, output_dtype="object", suffix="_maxlikelihood"):
        self._target_variable_name = target_variable_name
        self._distribution = None
        self._output_dtype = output_dtype
        self._suffix = suffix

    def setup(self, network, inference_engine, query_options):
        distribution = None

        self._variable = bayespy.network.get_variable(network, self._target_variable_name)

        if bayespy.network.is_variable_discrete(self._variable):
            distribution = bayesServer().Table(self._variable)

        if distribution is None:
            raise ValueError("{} needs to be discrete in QueryMostLikelyState".format(self._target_variable_name))

        query_options.setQueryEvidenceMode(bayesServerInference().QueryEvidenceMode.RETRACT_QUERY_EVIDENCE)
        qd = bayesServerInference().QueryDistribution(distribution)

        self._distribution = distribution
        inference_engine.getQueryDistributions().add(qd)

    def results(self, inference_engine, query_output):
        states = {}
        for state in self._variable.getStates():
            states.update({ state.getName() : self._distribution.get([state])})

        # get the most likely state
        max_state = max(states.keys(), key=(lambda key: states[key]))
        max_state_name = bayespy.data.DataFrame.cast2(self._output_dtype, max_state)

        return {self._target_variable_name + self._suffix: max_state_name}

class QueryLogLikelihood:
    def __init__(self, variable_names, column_name: str='_loglikelihood'):
        if isinstance(variable_names, str):
            variable_names = [variable_names]

        self._variable_names = variable_names
        self._distribution = None
        self._query_distribution = None


        self._column_name = column_name

    def setup(self, network, inference_engine, query_options):
        variables = [bayespy.network.get_variable(network, n) for n in self._variable_names]
        if len(variables) == 1:
            self._distribution = bayesServer().CLGaussian(variables[0])
        else:
            self._distribution = bayesServer().CLGaussian(variables)

        query_options.setQueryEvidenceMode(bayesServerInference().QueryEvidenceMode.RETRACT_QUERY_EVIDENCE)
        qd = bayesServerInference().QueryDistribution(self._distribution)
        qd.setQueryLogLikelihood(True)
        self._query_distribution = qd
        inference_engine.getQueryDistributions().add(qd)

    def results(self, inference_engine, query_output):
        result = {}
        ll = self._query_distribution.getLogLikelihood()
        value = ll.floatValue() if ll is not None else np.nan
        result.update({":".join(self._variable_names) + self._column_name: value})
        return result

class QueryMeanVariance:
    def __init__(self, variable_name, retract_evidence=True, result_mean_suffix='_mean', result_variance_suffix='_variance'):
        self._variable_name = variable_name

        self._result_mean_suffix = result_mean_suffix
        self._result_variance_suffix = result_variance_suffix
        self._retract_evidence = retract_evidence

    def setup(self, network, inference_engine, query_options):
        self._variable = bayespy.network.get_variable(network, self._variable_name)

        if not bayespy.network.is_variable_continuous(self._variable):
            raise ValueError("{} needs to be continuous.".format(self._variable_name))

        self._query = bayesServer().CLGaussian(self._variable)

        if self._retract_evidence:
            query_options.setQueryEvidenceMode(bayesServerInference().QueryEvidenceMode.RETRACT_QUERY_EVIDENCE)

        inference_engine.getQueryDistributions().add(bayesServerInference().QueryDistribution(self._query))

    def results(self, inference_engine, query_output):
        return {self._variable_name + self._result_mean_suffix: self._query.getMean(self._variable),
                self._variable_name + self._result_variance_suffix: self._query.getVariance(self._variable)}

def _batch_query(df: pd.DataFrame, connection_string: str, network: str, table_name: str,
                 variable_references: List[str],
                 queries, logger, i):

    bayespy.jni.attach()
    network = bayespy.network.create_network_from_string(network)

    reader_options = bayesServer().data.ReaderOptions("ix")
    variable_refs = list(bayespy.network.create_variable_references(network, df,
                                                                    variable_references=variable_references))

    data_reader = bayesServer().data.DatabaseDataReaderCommand(
        connection_string,
        "select * from {} where ix in ({})".format(table_name, ",".join(str(i) for i in df.index.tolist()))).executeReader()

    reader = bayesServer().data.DefaultEvidenceReader(data_reader, jp.java.util.Arrays.asList(variable_refs),
                                                   reader_options)


    factory = InferenceEngine(network)
    (inference_engine, query_options, query_output) = factory.create()

    for query in queries:
        query.setup(network, inference_engine, query_options)

    results = []
    try:
        while reader.read(inference_engine.getEvidence(), bayesServer().data.DefaultReadOptions(True)):
            result = {}

            try:
                inference_engine.query(query_options, query_output)
            except BaseException as e:
                logger.error(e)
                # inference_engine.getEvidence().clear()
                # continue

            for query in queries:
                result = {**result, **query.results(inference_engine, query_output)}

            inference_engine.getEvidence().clear()
            result.update({'caseid': int(reader.getReadInfo().getCaseId().toString())})

            results.append(result)

            if i % 500 == 0:
                logger.info("Queried case {}".format(i))

            i += 1
    finally:
        reader.close()
        #bayespy.jni.detach()
        return results


class BatchQuery:

    def __init__(self, network, datastore, logger: logging.Logger):

        self._logger = logger
        self._datastore = datastore
        # serialise the network as a string.
        self._network = network.saveToString()

    def _calc_num_threads(self, df_size: int, query_size: int):
        num_queries = df_size * query_size

        max = mp.cpu_count() - 2
        calc = int(num_queries / 5000)
        if calc > max:
            return max

        if calc <= 1:
            if num_queries > 1000:
                return 2

            return 1

        return calc


    def query(self, queries=[QueryStatistics()], append_to_df=True, variable_references=[]):

        if not hasattr(queries, "__getitem__"):
            queries = [queries]

        nt = self._network
        logger = self._logger
        conn = self._datastore.get_connection()
        table = self._datastore.table
        processes = self._calc_num_threads(len(self._datastore.data), len(queries))
        if processes == 1:
            pdf = pd.DataFrame(_batch_query(self._datastore.data, conn, nt, table,
                         variable_references, queries,
                         logger, 0))
        else:
            with mp.Pool(processes=processes) as pool:
                pdf = pd.DataFrame()
                for result_set in pool.map(lambda df: _batch_query(df, conn, nt, table,
                                                                 variable_references, queries,
                                                                logger, 0), np.array_split(self._datastore.data, processes)):
                    pdf = pdf.append(pd.DataFrame(result_set))

        df = pdf.set_index('caseid')

        if append_to_df:
            return self._datastore.data.join(df)
        else:
            return df


class NetworkModel:

    def __init__(self, network, data_store, logger):
        self._jnetwork = network
        self._inference_factory = InferenceEngine(network)
        self._data_store = data_store
        self._logger = logger
        self._data = data_store.data

    def get_network(self):
        return self._jnetwork

    def save(self, path):
        from xml.dom import minidom
        nt = self._jnetwork.saveToString()
        reparsed = minidom.parseString(nt)
        with open(path, 'w') as fh:
            fh.write(reparsed.toprettyxml(indent="  "))

    def is_trained(self):
        return bayespy.network.is_trained(self._jnetwork)

    def train(self):
        """
        Train a model on data provided in the constructor
        """
        learning = bayesServerParams().ParameterLearning(self._jnetwork, self._inference_factory.get_inference_factory())
        learning_options = bayesServerParams().ParameterLearningOptions()

        data_reader_command = self._data_store.create_data_reader_command()

        reader_options = bayesServer().data.ReaderOptions()

        variable_references = list(bayespy.network.create_variable_references(self._jnetwork, self._data))

        evidence_reader_command = bayesServer().data.DefaultEvidenceReaderCommand(data_reader_command,
                                            jp.java.util.Arrays.asList(variable_references), reader_options)

        self._logger.info("Training model...")
        result = learning.learn(evidence_reader_command, learning_options)
        self._logger.info("Finished training model")

        return {'Converged': result.getConverged(), 'Loglikelihood': result.getLogLikelihood().floatValue(),
                    'IterationCount': result.getIterationCount(), 'CaseCount': result.getCaseCount(),
                    'WeightedCaseCount': result.getWeightedCaseCount(), 'UnweightedCaseCount':  result.getUnweightedCaseCount(),
                    'BIC': result.getBIC().floatValue()}


    def batch_query(self, queries=[QueryStatistics()], append_to_df=True, variable_references=[]):
        bq = BatchQuery(self._jnetwork, self._data_store, self._logger)
        return bq.query(queries, append_to_df=append_to_df, variable_references=variable_references)